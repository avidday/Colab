{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNX+dqE6fNcpP1QQwzD22/H",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avidday/Colab/blob/main/nvcc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK1F1pIox20o",
        "outputId": "e5bcd630-a362-4ab6-e194-6852b1860663"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 5613745939228488385\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14328594432\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 16659905244804770787\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC0J-k8MxiYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6288a1df-0345-4f62-bf60-c2ac320ff397"
      },
      "source": [
        "!ls /usr/local/cuda/bin\n",
        "!nvcc --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin2c\t\t   cuda-gdb\t   cuobjdump\t\tnvcc.profile  nvprune\n",
            "compute-sanitizer  cuda-gdbserver  fatbinary\t\tnvdisasm      ptxas\n",
            "crt\t\t   cuda-memcheck   nvcc\t\t\tnvlink\n",
            "cudafe++\t   cu++filt\t   __nvcc_device_query\tnvprof\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile p4x4det.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <algorithm>\n",
        "#include <cstdio>\n",
        "#include <cub/block/block_load.cuh>\n",
        "#include <cub/block/block_store.cuh>\n",
        "#include <cub/block/block_exchange.cuh>\n",
        "#include <cuda/std/complex>\n",
        "\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess) \n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "\n",
        "const int _3x3 = 9;\n",
        "const int _4x4 = 16;\n",
        "const int _5x5 = 25;\n",
        "\n",
        "typedef cuda::std::complex<float> cfloat;\n",
        "typedef cuda::std::complex<double> cdouble;\n",
        "\n",
        "template<typename T>\n",
        "__device__ __host__\n",
        "void repr(T x) { printf(\"unknown type\"); }\n",
        "\n",
        "template<>\n",
        "__device__ __host__\n",
        "void repr(const char *x) { printf(\"%s\", x); }\n",
        "\n",
        "template<>\n",
        "__device__ __host__\n",
        "void repr(float x) { printf(\"%f \", x); }\n",
        "\n",
        "template<>\n",
        "__device__ __host__\n",
        "void repr(cfloat x) { printf(\"%f + i%f \", x.real(), x.imag()); }\n",
        "\n",
        "template<>\n",
        "__device__ __host__\n",
        "void repr(double x) { printf(\"%lf \", x); }\n",
        "\n",
        "template<>\n",
        "__device__ __host__\n",
        "void repr(cdouble x) { printf(\"%lf + i%lf \", x.real(), x.imag()); }\n",
        "\n",
        "template<typename T, typename... Ts>\n",
        "__device__ __host__\n",
        "void repr(T x, Ts... args)\n",
        "{\n",
        "    repr(x);\n",
        "    repr(args...);\n",
        "}\n",
        "\n",
        "template<typename T, bool verbose=false>\n",
        "__device__ __host__ __forceinline__ \n",
        "T det2x2(T a11, T a12, \n",
        "         T a21, T a22)\n",
        "{\n",
        "    auto mul = [&] (T x, T y)      { return x * y; };\n",
        "    auto fma = [&] (T x, T y, T z) { return mul(x, y) + z; };\n",
        "\n",
        " \n",
        "    T a12_a21 = mul(-a12, a21);\n",
        "    T det = fma(a11, a22, a12_a21);\n",
        "\n",
        "    if (verbose) {\n",
        "        repr(a11, a12, \"\\n\");\n",
        "        repr(a21, a22, \"\\n\");\n",
        "        repr(\"det = \", det, \"\\n\");\n",
        "    }\n",
        "\n",
        "    return det;\n",
        "}\n",
        "\n",
        "template<typename T, bool verbose=false>\n",
        "__device__ __host__ __forceinline__ \n",
        "T det3x3(T a11, T a12, T a13, \n",
        "         T a21, T a22, T a23, \n",
        "         T a31, T a32, T a33)\n",
        "{\n",
        "    auto mul = [&] (T x, T y)      { return x * y; };\n",
        "    auto fma = [&] (T x, T y, T z) { return mul(x, y) + z; };\n",
        "\n",
        "    T a23_a32 = mul(-a23, a32);\n",
        "    T a13_a32 = mul(-a13, a32);\n",
        "    T a13_a22 = mul(-a13, a22);\n",
        "\n",
        "    T det_22_33 = det2x2<T,false>(a22, a23,\n",
        "                                  a32, a33);\n",
        "    T det_12_13 = det2x2<T,false>(a12, a13,\n",
        "                                  a32, a33);\n",
        "    T det_12_23 = det2x2<T,false>(a12, a13, \n",
        "                                  a22, a23);\n",
        "\n",
        "    T det = mul( a11, det_22_33);\n",
        "    det =   fma(-a21, det_12_13, det);\n",
        "    det =   fma( a31, det_12_23, det);\n",
        "\n",
        "    if (verbose) {\n",
        "        repr(a11, a12, a13, \"\\n\");\n",
        "        repr(a21, a22, a23, \"\\n\");\n",
        "        repr(a31, a32, a33, \"\\n\");\n",
        "        repr(\"det = \", det, \"\\n\"); \n",
        "    }\n",
        "\n",
        "    return det;\n",
        "}\n",
        "\n",
        "template <typename T, bool verbose=false>\n",
        "__device__ __host__ __forceinline__\n",
        "T det4x4(T a11, T a12, T a13, T a14, \n",
        "         T a21, T a22, T a23, T a24, \n",
        "         T a31, T a32, T a33, T a34, \n",
        "         T a41, T a42, T a43, T a44)\n",
        "{\n",
        "    auto mul = [&] (T x, T y)      { return x * y; };\n",
        "    auto fma = [&] (T x, T y, T z) { return mul(x, y) + z; };\n",
        "\n",
        "    T det_22_33_44 = det3x3<T,false>\n",
        "                           (a22, a23, a24,\n",
        "                            a32, a33, a34,\n",
        "                            a42, a43, a44);\n",
        "\n",
        "    T det_12_33_44 = det3x3<T,false>\n",
        "                           (a12, a13, a14,\n",
        "                            a32, a33, a34,\n",
        "                            a42, a43, a44);\n",
        "\n",
        "    T det_12_23_44 = det3x3<T,false>\n",
        "                           (a12, a13, a14,\n",
        "                            a22, a23, a24,\n",
        "                            a42, a43, a44);\n",
        "\n",
        "    T det_12_23_34 = det3x3<T,false>\n",
        "                           (a12, a13, a14,\n",
        "                            a22, a23, a24,\n",
        "                            a32, a33, a34);\n",
        "\n",
        "    T det;\n",
        "    det = mul( a11, det_22_33_44);\n",
        "    det = fma(-a21, det_12_33_44, det);\n",
        "    det = fma( a31, det_12_23_44, det);\n",
        "    det = fma(-a41, det_12_23_34, det);\n",
        "\n",
        "    if (verbose) {\n",
        "        repr(a11, a12, a13, a14, \"\\n\");\n",
        "        repr(a21, a22, a23, a24, \"\\n\");\n",
        "        repr(a31, a32, a33, a34, \"\\n\");\n",
        "        repr(a41, a42, a43, a44, \"\\n\");\n",
        "        repr(\"det = \", det, \"\\n\");\n",
        "    }\n",
        "\n",
        "    return det;                        \n",
        "}\n",
        "\n",
        "template <typename T, bool verbose=false>\n",
        "__device__ __host__ __forceinline__\n",
        "T det5x5(T a11, T a12, T a13, T a14, T a15,\n",
        "         T a21, T a22, T a23, T a24, T a25,\n",
        "         T a31, T a32, T a33, T a34, T a35,\n",
        "         T a41, T a42, T a43, T a44, T a45,\n",
        "         T a51, T a52, T a53, T a54, T a55)     \n",
        "{\n",
        "    auto mul = [&] (T x, T y)      { return x * y; };\n",
        "    auto fma = [&] (T x, T y, T z) { return mul(x, y) + z; };\n",
        "\n",
        "    T det_22_33_44_55 = det4x4<T,false>\n",
        "                           (a22, a23, a24, a25,\n",
        "                            a32, a33, a34, a35,\n",
        "                            a42, a43, a44, a45,\n",
        "                            a52, a53, a54, a55);\n",
        "\n",
        "    T det_12_33_44_55 = det4x4<T,false>\n",
        "                           (a12, a13, a14, a15,\n",
        "                            a32, a33, a34, a35,\n",
        "                            a42, a43, a44, a45,\n",
        "                            a52, a53, a54, a55);\n",
        "\n",
        "    T det_12_23_44_55 = det4x4<T,false>\n",
        "                           (a12, a13, a14, a15,\n",
        "                            a22, a23, a24, a25,\n",
        "                            a42, a43, a44, a45,\n",
        "                            a52, a53, a54, a55);\n",
        "\n",
        "    T det_12_23_34_55 = det4x4<T,false>\n",
        "                           (a12, a13, a14, a15,\n",
        "                            a22, a23, a24, a25,\n",
        "                            a32, a33, a34, a35,\n",
        "                            a52, a53, a54, a55);\n",
        "\n",
        "    T det_12_23_34_45 = det4x4<T,false>\n",
        "                           (a12, a13, a14, a15,\n",
        "                            a22, a23, a24, a25,\n",
        "                            a32, a33, a34, a35,\n",
        "                            a42, a43, a44, a45);\n",
        "                            \n",
        "\n",
        "    T det;\n",
        "    det = mul( a11, det_22_33_44_55);\n",
        "    det = fma(-a21, det_12_33_44_55, det);\n",
        "    det = fma( a31, det_12_23_44_55, det);\n",
        "    det = fma(-a41, det_12_23_34_55, det);\n",
        "    det = fma( a51, det_12_23_34_45, det);\n",
        "\n",
        "    if (verbose) {\n",
        "        repr(a11, a12, a13, a14, a15, \"\\n\");\n",
        "        repr(a21, a22, a23, a24, a25, \"\\n\");\n",
        "        repr(a31, a32, a33, a34, a35, \"\\n\");\n",
        "        repr(a41, a42, a43, a44, a45, \"\\n\");\n",
        "        repr(a51, a52, a53, a54, a55, \"\\n\");\n",
        "        repr(\"det = \", det, \"\\n\");\n",
        "    }\n",
        "\n",
        "    return det;                        \n",
        "}\n",
        "\n",
        "template <typename T, int mdim, int blocksz>\n",
        "__global__ void detkernel(T *d_data, T *d_result, int Nmatrix)\n",
        "{\n",
        "    typedef cub::BlockLoad<T, blocksz, mdim, cub::BLOCK_LOAD_STRIPED> BlockLoad;\n",
        "    typedef cub::BlockStore<T, blocksz, 1, cub::BLOCK_STORE_DIRECT> BlockStore;\n",
        "    typedef cub::BlockExchange<T, blocksz, mdim> BlockExchange;\n",
        "\n",
        "    __shared__ \n",
        "    union {\n",
        "\t    typename BlockLoad::TempStorage load;\n",
        "      typename BlockStore::TempStorage store;\n",
        "      typename BlockExchange::TempStorage exchange;\n",
        "    } temp;\n",
        "\n",
        "    T thread_data[mdim], l_result[1];\n",
        "    T det;\n",
        "\n",
        "    BlockLoad(temp.load).Load(d_data, thread_data, Nmatrix * mdim);\n",
        "    __syncthreads();\n",
        "\n",
        "    BlockExchange(temp.exchange).StripedToBlocked(thread_data);\n",
        "\n",
        "    switch(mdim) {\n",
        "      case _3x3:\n",
        "      {\n",
        "        T a11 = thread_data[0];      T a21 = thread_data[3+0];\n",
        "        T a12 = thread_data[1];      T a22 = thread_data[3+1];\n",
        "        T a13 = thread_data[2];      T a23 = thread_data[3+2];\n",
        "\n",
        "        T a31 = thread_data[6+0];\n",
        "        T a32 = thread_data[6+1];\n",
        "        T a33 = thread_data[6+2];\n",
        "\n",
        "        det = det3x3<T, false>( \n",
        "                        a11, a12, a13,\n",
        "                        a21, a22, a23,\n",
        "                        a31, a32, a33);\n",
        "      } \n",
        "      break;\n",
        "\n",
        "      case _4x4:\n",
        "      {\n",
        "        T a11 = thread_data[0];      T a21 = thread_data[4+0];\n",
        "        T a12 = thread_data[1];      T a22 = thread_data[4+1];\n",
        "        T a13 = thread_data[2];      T a23 = thread_data[4+2];\n",
        "        T a14 = thread_data[3];      T a24 = thread_data[4+3];\n",
        "\n",
        "        T a31 = thread_data[8+0];    T a41 = thread_data[12+0];\n",
        "        T a32 = thread_data[8+1];    T a42 = thread_data[12+1];\n",
        "        T a33 = thread_data[8+2];    T a43 = thread_data[12+2];\n",
        "        T a34 = thread_data[8+3];    T a44 = thread_data[12+3];\n",
        "\n",
        "        det = det4x4<T, false>( \n",
        "                        a11, a12, a13, a14,\n",
        "                        a21, a22, a23, a24,\n",
        "                        a31, a32, a33, a34,\n",
        "                        a41, a42, a43, a44);\n",
        "      } \n",
        "      break;\n",
        "\n",
        "      case _5x5:\n",
        "      {\n",
        "        T a11 = thread_data[0];      T a21 = thread_data[5+0];\n",
        "        T a12 = thread_data[1];      T a22 = thread_data[5+1];\n",
        "        T a13 = thread_data[2];      T a23 = thread_data[5+2];\n",
        "        T a14 = thread_data[3];      T a24 = thread_data[5+3];\n",
        "        T a15 = thread_data[4];      T a25 = thread_data[5+4];\n",
        "\n",
        "        T a31 = thread_data[10+0];    T a41 = thread_data[15+0];\n",
        "        T a32 = thread_data[10+1];    T a42 = thread_data[15+1];\n",
        "        T a33 = thread_data[10+2];    T a43 = thread_data[15+2];\n",
        "        T a34 = thread_data[10+3];    T a44 = thread_data[15+3];\n",
        "        T a35 = thread_data[10+4];    T a45 = thread_data[15+4];\n",
        "\n",
        "        T a51 = thread_data[20+0];\n",
        "        T a52 = thread_data[20+1];\n",
        "        T a53 = thread_data[20+2];\n",
        "        T a54 = thread_data[20+3];\n",
        "        T a55 = thread_data[20+4];\n",
        "        det = det5x5<T, false>( \n",
        "                        a11, a12, a13, a14, a15,\n",
        "                        a21, a22, a23, a24, a25, \n",
        "                        a31, a32, a33, a34, a35, \n",
        "                        a41, a42, a43, a44, a45,\n",
        "                        a51, a52, a53, a54, a55);\n",
        "      }\n",
        "\n",
        "      break;\n",
        "    }\n",
        "\n",
        "    l_result[0] = det;\n",
        "    BlockStore(temp.store).Store(d_result, l_result, Nmatrix); \n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "//template __global__ void detkernel<float,_3x3>(float *, float *, int);\n",
        "//template __global__ void detkernel<float,_4x4>(float *, float *, int);\n",
        "//template __global__ void detkernel<float,_5x5>(float *, float *, int);\n",
        "\n",
        "//template __global__ void detkernel<cfloat,_3x3>(cfloat *, cfloat *, int);\n",
        "//template __global__ void detkernel<cfloat,_4x4>(cfloat *, cfloat *, int);\n",
        "//template __global__ void detkernel<cfloat,_5x5>(cfloat *, cfloat *, int);\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int nmatrices = 128;\n",
        "\n",
        "    // triadiagonal laplacian 5x5\n",
        "    std::vector<float> iarray(_5x5);\n",
        "    iarray[0] = -4.f; iarray[1] =  2.f; iarray[2] =   0.f; iarray[3] =   0.f; iarray[4] =  0.f; \n",
        "    iarray[5] =  1.f; iarray[6] = -4.f; iarray[7] =   1.f; iarray[8] =   0.f; iarray[9] =  0.f;\n",
        "    iarray[10] = 0.f; iarray[11] = 1.f; iarray[12] = -4.f; iarray[13] =  1.f; iarray[14] =  0.f;\n",
        "    iarray[15] = 0.f; iarray[16] = 0.f; iarray[17] =  1.f; iarray[18] = -4.f; iarray[19] =  1.f;\n",
        "    iarray[20] = 0.f; iarray[21] = 0.f; iarray[22] =  0.f; iarray[23] =  2.f; iarray[24] = -4.f;\n",
        "\n",
        "    float det3 = det3x3<float,true>\n",
        "                              (iarray[   0], iarray[   1], iarray[   2],\n",
        "                               iarray[ 3+0], iarray[ 3+1], iarray[ 3+2],\n",
        "                               iarray[ 6+0], iarray[ 6+1], iarray[ 6+2]);\n",
        "\n",
        "    std::cout << \"Reference solution 3x3 = \" << det3 << std::endl;\n",
        "\n",
        "\n",
        "    float det4 = det4x4<float,true>\n",
        "                              (iarray[   0], iarray[   1], iarray[   2], iarray[   3],\n",
        "                               iarray[ 5+0], iarray[ 5+1], iarray[ 5+2], iarray[ 5+3],\n",
        "                               iarray[10+0], iarray[10+1], iarray[10+2], iarray[10+3],\n",
        "                               iarray[15+0], iarray[15+1], iarray[15+2], iarray[15+3]);\n",
        "\n",
        "    std::cout << \"Reference solution 4x4 = \" << det4 << std::endl;\n",
        "\n",
        "    float det5 = det5x5<float,true>\n",
        "                              (iarray[   0], iarray[   1], iarray[   2], iarray[   3], iarray[   4],\n",
        "                               iarray[ 5+0], iarray[ 5+1], iarray[ 5+2], iarray[ 5+3], iarray[ 5+4],\n",
        "                               iarray[10+0], iarray[10+1], iarray[10+2], iarray[10+3], iarray[10+4],\n",
        "                               iarray[15+0], iarray[15+1], iarray[15+2], iarray[15+3], iarray[15+4],\n",
        "                               iarray[20+0], iarray[20+1], iarray[20+2], iarray[20+3], iarray[20+4]\n",
        "                               );\n",
        "\n",
        "    std::cout << \"Reference solution 5x5 = \" << det5 << std::endl;\n",
        "\n",
        "    float *d_array, *d_result;\n",
        "    gpuErrchk( cudaMalloc(&d_array, nmatrices * _5x5 * sizeof(float)) );\n",
        "    gpuErrchk( cudaMalloc(&d_result, nmatrices * sizeof(float)) )\n",
        "    \n",
        "    float *p = d_array;\n",
        "    for(int i=0; i<nmatrices; i++) {\n",
        "    \tgpuErrchk( cudaMemcpy(p, &iarray[0], _5x5 * sizeof(float), cudaMemcpyHostToDevice) );\n",
        "      p += _5x5;\n",
        "      std::for_each(iarray.begin(), iarray.end(), [](float &x){ x*=1.001f;} );\n",
        "    }\n",
        "    const int blocksz = 128;\n",
        "    int nblocks = (nmatrices / blocksz) + ((nmatrices % blocksz) ? 0 : 1);\n",
        "    detkernel<float,_5x5,blocksz><<<nblocks,blocksz>>>(d_array, d_result, nmatrices);\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "\n",
        "    std::vector<float> result(nmatrices, -1.f);\n",
        "    gpuErrchk( cudaMemcpy(&result[0], d_result, nmatrices * sizeof(float), cudaMemcpyDeviceToHost) );\n",
        "    for(int i=0; i<nmatrices; i++) {\n",
        "    \tstd::cout << result[i] << std::endl;\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnriyL5v6cqx",
        "outputId": "b1c9d759-eae7-4843-cb57-29b4a81bc0b8"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting p4x4det.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -Xptxas=\"-v\" -o p4x4det p4x4det.cu"
      ],
      "metadata": {
        "id": "K5swhlA7Smj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea19a73b-b957-45e9-9678-71acc7e584c8"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_ZN3cub11EmptyKernelIvEEvv' for 'sm_75'\n",
            "ptxas info    : Function properties for _ZN3cub11EmptyKernelIvEEvv\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 4 registers, 352 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z9detkernelIfLi25ELi128EEvPT_S1_i' for 'sm_75'\n",
            "ptxas info    : Function properties for _Z9detkernelIfLi25ELi128EEvPT_S1_i\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 58 registers, 12800 bytes smem, 372 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -ptx p4x4det.cu\n",
        "!cat p4x4det.ptx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1YjLd9LIdUX",
        "outputId": "edf7c33f-c2c5-437c-b4ea-701c11106541"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "//\n",
            "// Generated by NVIDIA NVVM Compiler\n",
            "//\n",
            "// Compiler Build ID: CL-31833905\n",
            "// Cuda compilation tools, release 11.8, V11.8.89\n",
            "// Based on NVVM 7.0.1\n",
            "//\n",
            "\n",
            ".version 7.8\n",
            ".target sm_75\n",
            ".address_size 64\n",
            "\n",
            "\t// .globl\t_Z9detkernelIfLi25ELi32EEvPT_S1_i\n",
            "// _ZZ9detkernelIfLi25ELi32EEvPT_S1_iE4temp has been demoted\n",
            "\n",
            ".visible .entry _Z9detkernelIfLi25ELi32EEvPT_S1_i(\n",
            "\t.param .u64 _Z9detkernelIfLi25ELi32EEvPT_S1_i_param_0,\n",
            "\t.param .u64 _Z9detkernelIfLi25ELi32EEvPT_S1_i_param_1,\n",
            "\t.param .u32 _Z9detkernelIfLi25ELi32EEvPT_S1_i_param_2\n",
            ")\n",
            "{\n",
            "\t.reg .pred \t%p<27>;\n",
            "\t.reg .f32 \t%f<233>;\n",
            "\t.reg .b32 \t%r<33>;\n",
            "\t.reg .b64 \t%rd<9>;\n",
            "\t// demoted variable\n",
            "\t.shared .align 16 .b8 _ZZ9detkernelIfLi25ELi32EEvPT_S1_iE4temp[3200];\n",
            "\n",
            "\tld.param.u64 \t%rd3, [_Z9detkernelIfLi25ELi32EEvPT_S1_i_param_0];\n",
            "\tld.param.u64 \t%rd2, [_Z9detkernelIfLi25ELi32EEvPT_S1_i_param_1];\n",
            "\tld.param.u32 \t%r3, [_Z9detkernelIfLi25ELi32EEvPT_S1_i_param_2];\n",
            "\tcvta.to.global.u64 \t%rd4, %rd3;\n",
            "\tmul.lo.s32 \t%r1, %r3, 25;\n",
            "\tmov.u32 \t%r2, %tid.x;\n",
            "\tsetp.ge.s32 \t%p1, %r2, %r1;\n",
            "\tmul.wide.s32 \t%rd5, %r2, 4;\n",
            "\tadd.s64 \t%rd1, %rd4, %rd5;\n",
            "\t@%p1 bra \t$L__BB0_2;\n",
            "\n",
            "\tld.global.f32 \t%f208, [%rd1];\n",
            "\n",
            "$L__BB0_2:\n",
            "\tadd.s32 \t%r4, %r2, 32;\n",
            "\tsetp.ge.s32 \t%p2, %r4, %r1;\n",
            "\t@%p2 bra \t$L__BB0_4;\n",
            "\n",
            "\tld.global.f32 \t%f209, [%rd1+128];\n",
            "\n",
            "$L__BB0_4:\n",
            "\tadd.s32 \t%r5, %r2, 64;\n",
            "\tsetp.ge.s32 \t%p3, %r5, %r1;\n",
            "\t@%p3 bra \t$L__BB0_6;\n",
            "\n",
            "\tld.global.f32 \t%f210, [%rd1+256];\n",
            "\n",
            "$L__BB0_6:\n",
            "\tadd.s32 \t%r6, %r2, 96;\n",
            "\tsetp.ge.s32 \t%p4, %r6, %r1;\n",
            "\t@%p4 bra \t$L__BB0_8;\n",
            "\n",
            "\tld.global.f32 \t%f211, [%rd1+384];\n",
            "\n",
            "$L__BB0_8:\n",
            "\tadd.s32 \t%r7, %r2, 128;\n",
            "\tsetp.ge.s32 \t%p5, %r7, %r1;\n",
            "\t@%p5 bra \t$L__BB0_10;\n",
            "\n",
            "\tld.global.f32 \t%f212, [%rd1+512];\n",
            "\n",
            "$L__BB0_10:\n",
            "\tadd.s32 \t%r8, %r2, 160;\n",
            "\tsetp.ge.s32 \t%p6, %r8, %r1;\n",
            "\t@%p6 bra \t$L__BB0_12;\n",
            "\n",
            "\tld.global.f32 \t%f213, [%rd1+640];\n",
            "\n",
            "$L__BB0_12:\n",
            "\tadd.s32 \t%r9, %r2, 192;\n",
            "\tsetp.ge.s32 \t%p7, %r9, %r1;\n",
            "\t@%p7 bra \t$L__BB0_14;\n",
            "\n",
            "\tld.global.f32 \t%f214, [%rd1+768];\n",
            "\n",
            "$L__BB0_14:\n",
            "\tadd.s32 \t%r10, %r2, 224;\n",
            "\tsetp.ge.s32 \t%p8, %r10, %r1;\n",
            "\t@%p8 bra \t$L__BB0_16;\n",
            "\n",
            "\tld.global.f32 \t%f215, [%rd1+896];\n",
            "\n",
            "$L__BB0_16:\n",
            "\tadd.s32 \t%r11, %r2, 256;\n",
            "\tsetp.ge.s32 \t%p9, %r11, %r1;\n",
            "\t@%p9 bra \t$L__BB0_18;\n",
            "\n",
            "\tld.global.f32 \t%f216, [%rd1+1024];\n",
            "\n",
            "$L__BB0_18:\n",
            "\tadd.s32 \t%r12, %r2, 288;\n",
            "\tsetp.ge.s32 \t%p10, %r12, %r1;\n",
            "\t@%p10 bra \t$L__BB0_20;\n",
            "\n",
            "\tld.global.f32 \t%f217, [%rd1+1152];\n",
            "\n",
            "$L__BB0_20:\n",
            "\tadd.s32 \t%r13, %r2, 320;\n",
            "\tsetp.ge.s32 \t%p11, %r13, %r1;\n",
            "\t@%p11 bra \t$L__BB0_22;\n",
            "\n",
            "\tld.global.f32 \t%f218, [%rd1+1280];\n",
            "\n",
            "$L__BB0_22:\n",
            "\tadd.s32 \t%r14, %r2, 352;\n",
            "\tsetp.ge.s32 \t%p12, %r14, %r1;\n",
            "\t@%p12 bra \t$L__BB0_24;\n",
            "\n",
            "\tld.global.f32 \t%f219, [%rd1+1408];\n",
            "\n",
            "$L__BB0_24:\n",
            "\tadd.s32 \t%r15, %r2, 384;\n",
            "\tsetp.ge.s32 \t%p13, %r15, %r1;\n",
            "\t@%p13 bra \t$L__BB0_26;\n",
            "\n",
            "\tld.global.f32 \t%f220, [%rd1+1536];\n",
            "\n",
            "$L__BB0_26:\n",
            "\tadd.s32 \t%r16, %r2, 416;\n",
            "\tsetp.ge.s32 \t%p14, %r16, %r1;\n",
            "\t@%p14 bra \t$L__BB0_28;\n",
            "\n",
            "\tld.global.f32 \t%f221, [%rd1+1664];\n",
            "\n",
            "$L__BB0_28:\n",
            "\tadd.s32 \t%r17, %r2, 448;\n",
            "\tsetp.ge.s32 \t%p15, %r17, %r1;\n",
            "\t@%p15 bra \t$L__BB0_30;\n",
            "\n",
            "\tld.global.f32 \t%f222, [%rd1+1792];\n",
            "\n",
            "$L__BB0_30:\n",
            "\tadd.s32 \t%r18, %r2, 480;\n",
            "\tsetp.ge.s32 \t%p16, %r18, %r1;\n",
            "\t@%p16 bra \t$L__BB0_32;\n",
            "\n",
            "\tld.global.f32 \t%f223, [%rd1+1920];\n",
            "\n",
            "$L__BB0_32:\n",
            "\tadd.s32 \t%r19, %r2, 512;\n",
            "\tsetp.ge.s32 \t%p17, %r19, %r1;\n",
            "\t@%p17 bra \t$L__BB0_34;\n",
            "\n",
            "\tld.global.f32 \t%f224, [%rd1+2048];\n",
            "\n",
            "$L__BB0_34:\n",
            "\tadd.s32 \t%r20, %r2, 544;\n",
            "\tsetp.ge.s32 \t%p18, %r20, %r1;\n",
            "\t@%p18 bra \t$L__BB0_36;\n",
            "\n",
            "\tld.global.f32 \t%f225, [%rd1+2176];\n",
            "\n",
            "$L__BB0_36:\n",
            "\tadd.s32 \t%r21, %r2, 576;\n",
            "\tsetp.ge.s32 \t%p19, %r21, %r1;\n",
            "\t@%p19 bra \t$L__BB0_38;\n",
            "\n",
            "\tld.global.f32 \t%f226, [%rd1+2304];\n",
            "\n",
            "$L__BB0_38:\n",
            "\tadd.s32 \t%r22, %r2, 608;\n",
            "\tsetp.ge.s32 \t%p20, %r22, %r1;\n",
            "\t@%p20 bra \t$L__BB0_40;\n",
            "\n",
            "\tld.global.f32 \t%f227, [%rd1+2432];\n",
            "\n",
            "$L__BB0_40:\n",
            "\tadd.s32 \t%r23, %r2, 640;\n",
            "\tsetp.ge.s32 \t%p21, %r23, %r1;\n",
            "\t@%p21 bra \t$L__BB0_42;\n",
            "\n",
            "\tld.global.f32 \t%f228, [%rd1+2560];\n",
            "\n",
            "$L__BB0_42:\n",
            "\tadd.s32 \t%r24, %r2, 672;\n",
            "\tsetp.ge.s32 \t%p22, %r24, %r1;\n",
            "\t@%p22 bra \t$L__BB0_44;\n",
            "\n",
            "\tld.global.f32 \t%f229, [%rd1+2688];\n",
            "\n",
            "$L__BB0_44:\n",
            "\tadd.s32 \t%r25, %r2, 704;\n",
            "\tsetp.ge.s32 \t%p23, %r25, %r1;\n",
            "\t@%p23 bra \t$L__BB0_46;\n",
            "\n",
            "\tld.global.f32 \t%f230, [%rd1+2816];\n",
            "\n",
            "$L__BB0_46:\n",
            "\tadd.s32 \t%r26, %r2, 736;\n",
            "\tsetp.ge.s32 \t%p24, %r26, %r1;\n",
            "\t@%p24 bra \t$L__BB0_48;\n",
            "\n",
            "\tld.global.f32 \t%f231, [%rd1+2944];\n",
            "\n",
            "$L__BB0_48:\n",
            "\tadd.s32 \t%r27, %r2, 768;\n",
            "\tsetp.ge.s32 \t%p25, %r27, %r1;\n",
            "\t@%p25 bra \t$L__BB0_50;\n",
            "\n",
            "\tld.global.f32 \t%f232, [%rd1+3072];\n",
            "\n",
            "$L__BB0_50:\n",
            "\tbar.sync \t0;\n",
            "\tshl.b32 \t%r29, %r2, 2;\n",
            "\tmov.u32 \t%r30, _ZZ9detkernelIfLi25ELi32EEvPT_S1_iE4temp;\n",
            "\tadd.s32 \t%r31, %r30, %r29;\n",
            "\tst.shared.f32 \t[%r31], %f208;\n",
            "\tst.shared.f32 \t[%r31+128], %f209;\n",
            "\tst.shared.f32 \t[%r31+256], %f210;\n",
            "\tst.shared.f32 \t[%r31+384], %f211;\n",
            "\tst.shared.f32 \t[%r31+512], %f212;\n",
            "\tst.shared.f32 \t[%r31+640], %f213;\n",
            "\tst.shared.f32 \t[%r31+768], %f214;\n",
            "\tst.shared.f32 \t[%r31+896], %f215;\n",
            "\tst.shared.f32 \t[%r31+1024], %f216;\n",
            "\tst.shared.f32 \t[%r31+1152], %f217;\n",
            "\tst.shared.f32 \t[%r31+1280], %f218;\n",
            "\tst.shared.f32 \t[%r31+1408], %f219;\n",
            "\tst.shared.f32 \t[%r31+1536], %f220;\n",
            "\tst.shared.f32 \t[%r31+1664], %f221;\n",
            "\tst.shared.f32 \t[%r31+1792], %f222;\n",
            "\tst.shared.f32 \t[%r31+1920], %f223;\n",
            "\tst.shared.f32 \t[%r31+2048], %f224;\n",
            "\tst.shared.f32 \t[%r31+2176], %f225;\n",
            "\tst.shared.f32 \t[%r31+2304], %f226;\n",
            "\tst.shared.f32 \t[%r31+2432], %f227;\n",
            "\tst.shared.f32 \t[%r31+2560], %f228;\n",
            "\tst.shared.f32 \t[%r31+2688], %f229;\n",
            "\tst.shared.f32 \t[%r31+2816], %f230;\n",
            "\tst.shared.f32 \t[%r31+2944], %f231;\n",
            "\tst.shared.f32 \t[%r31+3072], %f232;\n",
            "\tbar.sync \t0;\n",
            "\tmad.lo.s32 \t%r32, %r2, 100, %r30;\n",
            "\tld.shared.f32 \t%f77, [%r32+92];\n",
            "\tld.shared.f32 \t%f78, [%r32+76];\n",
            "\tmul.f32 \t%f79, %f78, %f77;\n",
            "\tld.shared.f32 \t%f80, [%r32+96];\n",
            "\tld.shared.f32 \t%f81, [%r32+72];\n",
            "\tmul.f32 \t%f82, %f81, %f80;\n",
            "\tsub.f32 \t%f83, %f82, %f79;\n",
            "\tld.shared.f32 \t%f84, [%r32+56];\n",
            "\tmul.f32 \t%f85, %f77, %f84;\n",
            "\tld.shared.f32 \t%f86, [%r32+52];\n",
            "\tmul.f32 \t%f87, %f86, %f80;\n",
            "\tsub.f32 \t%f88, %f87, %f85;\n",
            "\tmul.f32 \t%f89, %f81, %f84;\n",
            "\tmul.f32 \t%f90, %f86, %f78;\n",
            "\tsub.f32 \t%f91, %f90, %f89;\n",
            "\tld.shared.f32 \t%f92, [%r32+48];\n",
            "\tmul.f32 \t%f93, %f92, %f83;\n",
            "\tld.shared.f32 \t%f94, [%r32+68];\n",
            "\tmul.f32 \t%f95, %f88, %f94;\n",
            "\tsub.f32 \t%f96, %f93, %f95;\n",
            "\tld.shared.f32 \t%f97, [%r32+88];\n",
            "\tfma.rn.f32 \t%f98, %f91, %f97, %f96;\n",
            "\tld.shared.f32 \t%f99, [%r32+36];\n",
            "\tmul.f32 \t%f100, %f77, %f99;\n",
            "\tld.shared.f32 \t%f101, [%r32+32];\n",
            "\tmul.f32 \t%f102, %f101, %f80;\n",
            "\tsub.f32 \t%f103, %f102, %f100;\n",
            "\tmul.f32 \t%f104, %f81, %f99;\n",
            "\tmul.f32 \t%f105, %f101, %f78;\n",
            "\tsub.f32 \t%f106, %f105, %f104;\n",
            "\tld.shared.f32 \t%f107, [%r32+28];\n",
            "\tmul.f32 \t%f108, %f107, %f83;\n",
            "\tmul.f32 \t%f109, %f103, %f94;\n",
            "\tsub.f32 \t%f110, %f108, %f109;\n",
            "\tfma.rn.f32 \t%f111, %f106, %f97, %f110;\n",
            "\tmul.f32 \t%f112, %f86, %f99;\n",
            "\tmul.f32 \t%f113, %f101, %f84;\n",
            "\tsub.f32 \t%f114, %f113, %f112;\n",
            "\tmul.f32 \t%f115, %f107, %f88;\n",
            "\tmul.f32 \t%f116, %f103, %f92;\n",
            "\tsub.f32 \t%f117, %f115, %f116;\n",
            "\tfma.rn.f32 \t%f118, %f114, %f97, %f117;\n",
            "\tmul.f32 \t%f119, %f107, %f91;\n",
            "\tmul.f32 \t%f120, %f106, %f92;\n",
            "\tsub.f32 \t%f121, %f119, %f120;\n",
            "\tfma.rn.f32 \t%f122, %f94, %f114, %f121;\n",
            "\tld.shared.f32 \t%f123, [%r32+24];\n",
            "\tmul.f32 \t%f124, %f123, %f98;\n",
            "\tld.shared.f32 \t%f125, [%r32+44];\n",
            "\tmul.f32 \t%f126, %f111, %f125;\n",
            "\tsub.f32 \t%f127, %f124, %f126;\n",
            "\tld.shared.f32 \t%f128, [%r32+64];\n",
            "\tfma.rn.f32 \t%f129, %f128, %f118, %f127;\n",
            "\tld.shared.f32 \t%f130, [%r32+84];\n",
            "\tmul.f32 \t%f131, %f122, %f130;\n",
            "\tsub.f32 \t%f132, %f129, %f131;\n",
            "\tld.shared.f32 \t%f133, [%r32+16];\n",
            "\tmul.f32 \t%f134, %f77, %f133;\n",
            "\tld.shared.f32 \t%f135, [%r32+12];\n",
            "\tmul.f32 \t%f136, %f135, %f80;\n",
            "\tsub.f32 \t%f137, %f136, %f134;\n",
            "\tmul.f32 \t%f138, %f81, %f133;\n",
            "\tmul.f32 \t%f139, %f135, %f78;\n",
            "\tsub.f32 \t%f140, %f139, %f138;\n",
            "\tld.shared.f32 \t%f141, [%r32+8];\n",
            "\tmul.f32 \t%f142, %f141, %f83;\n",
            "\tmul.f32 \t%f143, %f137, %f94;\n",
            "\tsub.f32 \t%f144, %f142, %f143;\n",
            "\tfma.rn.f32 \t%f145, %f140, %f97, %f144;\n",
            "\tmul.f32 \t%f146, %f86, %f133;\n",
            "\tmul.f32 \t%f147, %f135, %f84;\n",
            "\tsub.f32 \t%f148, %f147, %f146;\n",
            "\tmul.f32 \t%f149, %f141, %f88;\n",
            "\tmul.f32 \t%f150, %f137, %f92;\n",
            "\tsub.f32 \t%f151, %f149, %f150;\n",
            "\tfma.rn.f32 \t%f152, %f148, %f97, %f151;\n",
            "\tmul.f32 \t%f153, %f141, %f91;\n",
            "\tmul.f32 \t%f154, %f140, %f92;\n",
            "\tsub.f32 \t%f155, %f153, %f154;\n",
            "\tfma.rn.f32 \t%f156, %f94, %f148, %f155;\n",
            "\tld.shared.f32 \t%f157, [%r32+4];\n",
            "\tmul.f32 \t%f158, %f157, %f98;\n",
            "\tmul.f32 \t%f159, %f145, %f125;\n",
            "\tsub.f32 \t%f160, %f158, %f159;\n",
            "\tfma.rn.f32 \t%f161, %f128, %f152, %f160;\n",
            "\tmul.f32 \t%f162, %f156, %f130;\n",
            "\tsub.f32 \t%f163, %f161, %f162;\n",
            "\tmul.f32 \t%f164, %f101, %f133;\n",
            "\tmul.f32 \t%f165, %f135, %f99;\n",
            "\tsub.f32 \t%f166, %f165, %f164;\n",
            "\tmul.f32 \t%f167, %f141, %f103;\n",
            "\tmul.f32 \t%f168, %f137, %f107;\n",
            "\tsub.f32 \t%f169, %f167, %f168;\n",
            "\tfma.rn.f32 \t%f170, %f166, %f97, %f169;\n",
            "\tmul.f32 \t%f171, %f141, %f106;\n",
            "\tmul.f32 \t%f172, %f140, %f107;\n",
            "\tsub.f32 \t%f173, %f171, %f172;\n",
            "\tfma.rn.f32 \t%f174, %f166, %f94, %f173;\n",
            "\tmul.f32 \t%f175, %f157, %f111;\n",
            "\tmul.f32 \t%f176, %f145, %f123;\n",
            "\tsub.f32 \t%f177, %f175, %f176;\n",
            "\tfma.rn.f32 \t%f178, %f128, %f170, %f177;\n",
            "\tmul.f32 \t%f179, %f174, %f130;\n",
            "\tsub.f32 \t%f180, %f178, %f179;\n",
            "\tmul.f32 \t%f181, %f141, %f114;\n",
            "\tmul.f32 \t%f182, %f148, %f107;\n",
            "\tsub.f32 \t%f183, %f181, %f182;\n",
            "\tfma.rn.f32 \t%f184, %f166, %f92, %f183;\n",
            "\tmul.f32 \t%f185, %f157, %f118;\n",
            "\tmul.f32 \t%f186, %f152, %f123;\n",
            "\tsub.f32 \t%f187, %f185, %f186;\n",
            "\tfma.rn.f32 \t%f188, %f125, %f170, %f187;\n",
            "\tmul.f32 \t%f189, %f184, %f130;\n",
            "\tsub.f32 \t%f190, %f188, %f189;\n",
            "\tmul.f32 \t%f191, %f157, %f122;\n",
            "\tmul.f32 \t%f192, %f156, %f123;\n",
            "\tsub.f32 \t%f193, %f191, %f192;\n",
            "\tfma.rn.f32 \t%f194, %f125, %f174, %f193;\n",
            "\tmul.f32 \t%f195, %f128, %f184;\n",
            "\tsub.f32 \t%f196, %f194, %f195;\n",
            "\tld.shared.f32 \t%f197, [%r32];\n",
            "\tmul.f32 \t%f198, %f197, %f132;\n",
            "\tld.shared.f32 \t%f199, [%r32+20];\n",
            "\tmul.f32 \t%f200, %f199, %f163;\n",
            "\tsub.f32 \t%f201, %f198, %f200;\n",
            "\tld.shared.f32 \t%f202, [%r32+40];\n",
            "\tfma.rn.f32 \t%f203, %f202, %f180, %f201;\n",
            "\tld.shared.f32 \t%f204, [%r32+60];\n",
            "\tmul.f32 \t%f205, %f204, %f190;\n",
            "\tsub.f32 \t%f206, %f203, %f205;\n",
            "\tld.shared.f32 \t%f207, [%r32+80];\n",
            "\tfma.rn.f32 \t%f51, %f207, %f196, %f206;\n",
            "\tsetp.ge.s32 \t%p26, %r2, %r3;\n",
            "\t@%p26 bra \t$L__BB0_52;\n",
            "\n",
            "\tcvta.to.global.u64 \t%rd6, %rd2;\n",
            "\tadd.s64 \t%rd8, %rd6, %rd5;\n",
            "\tst.global.f32 \t[%rd8], %f51;\n",
            "\n",
            "$L__BB0_52:\n",
            "\tret;\n",
            "\n",
            "}\n",
            "\t// .globl\t_ZN3cub11EmptyKernelIvEEvv\n",
            ".visible .entry _ZN3cub11EmptyKernelIvEEvv()\n",
            "{\n",
            "\n",
            "\n",
            "\n",
            "\tret;\n",
            "\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "iarray = np.empty(25)\n",
        "iarray[0] = -4.;  iarray[1] =  2.; iarray[2] =   0.; iarray[3] =   0.; iarray[4] =   0.;\n",
        "iarray[5] =  1.;  iarray[6] = -4.; iarray[7] =   1.; iarray[8] =   0.; iarray[9] =   0.;\n",
        "iarray[10] = 0.;  iarray[11] = 1.; iarray[12] = -4.; iarray[13] =  1.; iarray[14] =  0.;\n",
        "iarray[15] = 0.;  iarray[16] = 0.; iarray[17] =  1.; iarray[18] = -4.; iarray[19] =  1.;\n",
        "iarray[20] = 0.;  iarray[21] = 0.;  iarray[22] = 0.; iarray[23] =  2.; iarray[24] = -4.;\n",
        "\n",
        "x5 = np.reshape(iarray, (5,5));\n",
        "print(x5)\n",
        "print(\"5x5 result \", np.linalg.det(x5))\n",
        "\n",
        "x = x5[:-1, :-1]\n",
        "print(x)\n",
        "print(\"4x4 result \", np.linalg.det(x))\n",
        "\n",
        "x0 = x[:-1,:-1]\n",
        "print(x0)\n",
        "print(\"3x3 result\", np.linalg.det(x0))\n",
        "\n",
        "x1 = x[:-1,1:]\n",
        "print(x1)\n",
        "print(\"3x3 result\", np.linalg.det(x1))\n",
        "\n",
        "x2 = x[1:,:-1]\n",
        "print(x2)\n",
        "print(\"3x3 result\", np.linalg.det(x2))\n",
        "\n",
        "x3 = x[1:,1:]\n",
        "print(x3)\n",
        "print(\"3x3 result\", np.linalg.det(x3))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw4eBiUpsg8s",
        "outputId": "fd5720bc-b2c7-4b98-d8c4-e3559703609a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-4.  2.  0.  0.  0.]\n",
            " [ 1. -4.  1.  0.  0.]\n",
            " [ 0.  1. -4.  1.  0.]\n",
            " [ 0.  0.  1. -4.  1.]\n",
            " [ 0.  0.  0.  2. -4.]]\n",
            "5x5 result  -672.0\n",
            "[[-4.  2.  0.  0.]\n",
            " [ 1. -4.  1.  0.]\n",
            " [ 0.  1. -4.  1.]\n",
            " [ 0.  0.  1. -4.]]\n",
            "4x4 result  194.00000000000003\n",
            "[[-4.  2.  0.]\n",
            " [ 1. -4.  1.]\n",
            " [ 0.  1. -4.]]\n",
            "3x3 result -52.00000000000001\n",
            "[[ 2.  0.  0.]\n",
            " [-4.  1.  0.]\n",
            " [ 1. -4.  1.]]\n",
            "3x3 result 2.0\n",
            "[[ 1. -4.  1.]\n",
            " [ 0.  1. -4.]\n",
            " [ 0.  0.  1.]]\n",
            "3x3 result 1.0\n",
            "[[-4.  1.  0.]\n",
            " [ 1. -4.  1.]\n",
            " [ 0.  1. -4.]]\n",
            "3x3 result -56.00000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!compute-sanitizer ./p4x4det"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNO2Gd3QTB4I",
        "outputId": "93760e2c-0c56-4be4-b822-70b0a53cbe76"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= COMPUTE-SANITIZER\n",
            "-4.000000 2.000000 0.000000 \n",
            "0.000000 0.000000 1.000000 \n",
            "-4.000000 1.000000 0.000000 \n",
            "det = -4.000000 \n",
            "Reference solution 3x3 = -4\n",
            "-4.000000 2.000000 0.000000 0.000000 \n",
            "1.000000 -4.000000 1.000000 0.000000 \n",
            "0.000000 1.000000 -4.000000 1.000000 \n",
            "0.000000 0.000000 1.000000 -4.000000 \n",
            "det = 194.000000 \n",
            "Reference solution 4x4 = 194\n",
            "-4.000000 2.000000 0.000000 0.000000 0.000000 \n",
            "1.000000 -4.000000 1.000000 0.000000 0.000000 \n",
            "0.000000 1.000000 -4.000000 1.000000 0.000000 \n",
            "0.000000 0.000000 1.000000 -4.000000 1.000000 \n",
            "0.000000 0.000000 0.000000 2.000000 -4.000000 \n",
            "det = -672.000000 \n",
            "Reference solution 5x5 = -672\n",
            "-672\n",
            "-675.367\n",
            "-678.75\n",
            "-682.151\n",
            "-685.569\n",
            "-689.004\n",
            "-692.456\n",
            "-695.925\n",
            "-699.412\n",
            "-702.916\n",
            "-706.438\n",
            "-709.977\n",
            "-713.535\n",
            "-717.109\n",
            "-720.702\n",
            "-724.313\n",
            "-727.942\n",
            "-731.589\n",
            "-735.255\n",
            "-738.939\n",
            "-742.641\n",
            "-746.362\n",
            "-750.101\n",
            "-753.859\n",
            "-757.636\n",
            "-761.433\n",
            "-765.247\n",
            "-769.082\n",
            "-772.935\n",
            "-776.807\n",
            "-780.699\n",
            "-784.611\n",
            "-788.542\n",
            "-792.493\n",
            "-796.463\n",
            "-800.453\n",
            "-804.464\n",
            "-808.495\n",
            "-812.545\n",
            "-816.616\n",
            "-820.708\n",
            "-824.819\n",
            "-828.952\n",
            "-833.106\n",
            "-837.279\n",
            "-841.474\n",
            "-845.69\n",
            "-849.927\n",
            "-854.186\n",
            "-858.466\n",
            "-862.767\n",
            "-867.089\n",
            "-871.434\n",
            "-875.8\n",
            "-880.188\n",
            "-884.598\n",
            "-889.03\n",
            "-893.484\n",
            "-897.961\n",
            "-902.46\n",
            "-906.982\n",
            "-911.526\n",
            "-916.093\n",
            "-920.682\n",
            "-925.295\n",
            "-929.931\n",
            "-934.59\n",
            "-939.273\n",
            "-943.979\n",
            "-948.708\n",
            "-953.461\n",
            "-958.239\n",
            "-963.04\n",
            "-967.865\n",
            "-972.714\n",
            "-977.587\n",
            "-982.485\n",
            "-987.408\n",
            "-992.355\n",
            "-997.327\n",
            "-1002.32\n",
            "-1007.35\n",
            "-1012.39\n",
            "-1017.46\n",
            "-1022.56\n",
            "-1027.69\n",
            "-1032.83\n",
            "-1038.01\n",
            "-1043.21\n",
            "-1048.44\n",
            "-1053.69\n",
            "-1058.97\n",
            "-1064.27\n",
            "-1069.61\n",
            "-1074.97\n",
            "-1080.35\n",
            "-1085.76\n",
            "-1091.2\n",
            "-1096.67\n",
            "-1102.17\n",
            "-1107.69\n",
            "-1113.24\n",
            "-1118.82\n",
            "-1124.42\n",
            "-1130.05\n",
            "-1135.72\n",
            "-1141.41\n",
            "-1147.13\n",
            "-1152.87\n",
            "-1158.65\n",
            "-1164.45\n",
            "-1170.29\n",
            "-1176.15\n",
            "-1182.04\n",
            "-1187.97\n",
            "-1193.92\n",
            "-1199.9\n",
            "-1205.91\n",
            "-1211.95\n",
            "-1218.03\n",
            "-1224.13\n",
            "-1230.26\n",
            "-1236.43\n",
            "-1242.62\n",
            "-1248.85\n",
            "-1255.1\n",
            "-1261.39\n",
            "-1267.71\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./p4x4det"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8-7J-dFVEaT",
        "outputId": "6e0c8f21-1103-4c50-d6c1-35efaa35e8de"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-4.000000 2.000000 0.000000 \n",
            "0.000000 0.000000 1.000000 \n",
            "-4.000000 1.000000 0.000000 \n",
            "det = -4.000000 \n",
            "Reference solution 3x3 = -4\n",
            "-4.000000 2.000000 0.000000 0.000000 \n",
            "1.000000 -4.000000 1.000000 0.000000 \n",
            "0.000000 1.000000 -4.000000 1.000000 \n",
            "0.000000 0.000000 1.000000 -4.000000 \n",
            "det = 194.000000 \n",
            "Reference solution 4x4 = 194\n",
            "-4.000000 2.000000 0.000000 0.000000 0.000000 \n",
            "1.000000 -4.000000 1.000000 0.000000 0.000000 \n",
            "0.000000 1.000000 -4.000000 1.000000 0.000000 \n",
            "0.000000 0.000000 1.000000 -4.000000 1.000000 \n",
            "0.000000 0.000000 0.000000 2.000000 -4.000000 \n",
            "det = -672.000000 \n",
            "Reference solution 5x5 = -672\n",
            "==27122== NVPROF is profiling process 27122, command: ./p4x4det\n",
            "-672\n",
            "-675.367\n",
            "-678.75\n",
            "-682.151\n",
            "-685.569\n",
            "-689.004\n",
            "-692.456\n",
            "-695.925\n",
            "-699.412\n",
            "-702.916\n",
            "-706.438\n",
            "-709.977\n",
            "-713.535\n",
            "-717.109\n",
            "-720.702\n",
            "-724.313\n",
            "-727.942\n",
            "-731.589\n",
            "-735.255\n",
            "-738.939\n",
            "-742.641\n",
            "-746.362\n",
            "-750.101\n",
            "-753.859\n",
            "-757.636\n",
            "-761.433\n",
            "-765.247\n",
            "-769.082\n",
            "-772.935\n",
            "-776.807\n",
            "-780.699\n",
            "-784.611\n",
            "-788.542\n",
            "-792.493\n",
            "-796.463\n",
            "-800.453\n",
            "-804.464\n",
            "-808.495\n",
            "-812.545\n",
            "-816.616\n",
            "-820.708\n",
            "-824.819\n",
            "-828.952\n",
            "-833.106\n",
            "-837.279\n",
            "-841.474\n",
            "-845.69\n",
            "-849.927\n",
            "-854.186\n",
            "-858.466\n",
            "-862.767\n",
            "-867.089\n",
            "-871.434\n",
            "-875.8\n",
            "-880.188\n",
            "-884.598\n",
            "-889.03\n",
            "-893.484\n",
            "-897.961\n",
            "-902.46\n",
            "-906.982\n",
            "-911.526\n",
            "-916.093\n",
            "-920.682\n",
            "-925.295\n",
            "-929.931\n",
            "-934.59\n",
            "-939.273\n",
            "-943.979\n",
            "-948.708\n",
            "-953.461\n",
            "-958.239\n",
            "-963.04\n",
            "-967.865\n",
            "-972.714\n",
            "-977.587\n",
            "-982.485\n",
            "-987.408\n",
            "-992.355\n",
            "-997.327\n",
            "-1002.32\n",
            "-1007.35\n",
            "-1012.39\n",
            "-1017.46\n",
            "-1022.56\n",
            "-1027.69\n",
            "-1032.83\n",
            "-1038.01\n",
            "-1043.21\n",
            "-1048.44\n",
            "-1053.69\n",
            "-1058.97\n",
            "-1064.27\n",
            "-1069.61\n",
            "-1074.97\n",
            "-1080.35\n",
            "-1085.76\n",
            "-1091.2\n",
            "-1096.67\n",
            "-1102.17\n",
            "-1107.69\n",
            "-1113.24\n",
            "-1118.82\n",
            "-1124.42\n",
            "-1130.05\n",
            "-1135.72\n",
            "-1141.41\n",
            "-1147.13\n",
            "-1152.87\n",
            "-1158.65\n",
            "-1164.45\n",
            "-1170.29\n",
            "-1176.15\n",
            "-1182.04\n",
            "-1187.97\n",
            "-1193.92\n",
            "-1199.9\n",
            "-1205.91\n",
            "-1211.95\n",
            "-1218.03\n",
            "-1224.13\n",
            "-1230.26\n",
            "-1236.43\n",
            "-1242.62\n",
            "-1248.85\n",
            "-1255.1\n",
            "-1261.39\n",
            "-1267.71\n",
            "==27122== Profiling application: ./p4x4det\n",
            "==27122== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   95.63%  186.37us       128  1.4560us  1.4070us  1.7920us  [CUDA memcpy HtoD]\n",
            "                    3.25%  6.3360us         1  6.3360us  6.3360us  6.3360us  void detkernel<float, int=25, int=128>(float*, float*, int)\n",
            "                    1.12%  2.1760us         1  2.1760us  2.1760us  2.1760us  [CUDA memcpy DtoH]\n",
            "      API calls:   99.36%  207.45ms         2  103.72ms  4.1660us  207.44ms  cudaMalloc\n",
            "                    0.56%  1.1599ms       129  8.9910us  7.7220us  21.177us  cudaMemcpy\n",
            "                    0.05%  106.82us       101  1.0570us     127ns  44.809us  cuDeviceGetAttribute\n",
            "                    0.02%  37.354us         1  37.354us  37.354us  37.354us  cuDeviceGetName\n",
            "                    0.01%  23.955us         1  23.955us  23.955us  23.955us  cudaLaunchKernel\n",
            "                    0.00%  5.7150us         1  5.7150us  5.7150us  5.7150us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.8170us         3     605ns     199ns  1.3010us  cuDeviceGetCount\n",
            "                    0.00%  1.0160us         2     508ns     294ns     722ns  cuDeviceGet\n",
            "                    0.00%     453ns         1     453ns     453ns     453ns  cuModuleGetLoadingMode\n",
            "                    0.00%     338ns         1     338ns     338ns     338ns  cuDeviceTotalMem\n",
            "                    0.00%     301ns         1     301ns     301ns     301ns  cudaPeekAtLastError\n",
            "                    0.00%     248ns         1     248ns     248ns     248ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqTg4Epq6Cfr"
      },
      "source": []
    }
  ]
}